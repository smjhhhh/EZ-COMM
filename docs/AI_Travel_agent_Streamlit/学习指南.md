# ğŸ“ AI æ—…è¡Œä»£ç†å­¦ä¹ æŒ‡å—

## ğŸ“– å­¦ä¹ è·¯å¾„æ¦‚è§ˆ

æœ¬æŒ‡å—å°†å¸¦æ‚¨ä»é›¶å¼€å§‹ï¼Œé€æ­¥æ·±å…¥ç†è§£æ•´ä¸ªé¡¹ç›®çš„ä»£ç å’Œè®¾è®¡æ€è·¯ã€‚

### å­¦ä¹ è·¯çº¿å›¾

```
ç¬¬ä¸€é˜¶æ®µ: åŸºç¡€æ¦‚å¿µ (1-2 å°æ—¶)
  â”œâ”€â”€ Streamlit åŸºç¡€
  â”œâ”€â”€ ç¯å¢ƒå˜é‡ç®¡ç†
  â””â”€â”€ Python è£…é¥°å™¨

ç¬¬äºŒé˜¶æ®µ: AI æ¡†æ¶å…¥é—¨ (2-3 å°æ—¶)
  â”œâ”€â”€ LangChain ç®€ä»‹
  â”œâ”€â”€ å·¥å…·ï¼ˆToolsï¼‰æ¦‚å¿µ
  â””â”€â”€ å¤§è¯­è¨€æ¨¡å‹è°ƒç”¨

ç¬¬ä¸‰é˜¶æ®µ: æ ¸å¿ƒåŠŸèƒ½å®ç° (3-4 å°æ—¶)
  â”œâ”€â”€ è‡ªå®šä¹‰å·¥å…·å¼€å‘
  â”œâ”€â”€ ç³»ç»Ÿæç¤ºè¯è®¾è®¡
  â””â”€â”€ ä¼šè¯çŠ¶æ€ç®¡ç†

ç¬¬å››é˜¶æ®µ: é«˜çº§ç‰¹æ€§ (2-3 å°æ—¶)
  â”œâ”€â”€ LangGraph çŠ¶æ€å›¾
  â”œâ”€â”€ å·¥å…·é“¾ç¼–æ’
  â””â”€â”€ é”™è¯¯å¤„ç†ç­–ç•¥

ç¬¬äº”é˜¶æ®µ: å®æˆ˜ç»ƒä¹  (3-5 å°æ—¶)
  â”œâ”€â”€ æ·»åŠ æ–°åŠŸèƒ½
  â”œâ”€â”€ æ€§èƒ½ä¼˜åŒ–
  â””â”€â”€ éƒ¨ç½²ä¸Šçº¿
```

---

## ğŸŒŸ ç¬¬ä¸€é˜¶æ®µ: åŸºç¡€æ¦‚å¿µ

### 1.1 Streamlit å¿«é€Ÿå…¥é—¨

#### Streamlit æ˜¯ä»€ä¹ˆï¼Ÿ

Streamlit æ˜¯ä¸€ä¸ª Python Web æ¡†æ¶ï¼Œè®©æ‚¨å¯ä»¥ç”¨çº¯ Python ä»£ç åˆ›å»ºæ¼‚äº®çš„ Web åº”ç”¨ï¼Œæ— éœ€å­¦ä¹  HTML/CSS/JavaScriptã€‚

#### æœ€ç®€å•çš„ Streamlit åº”ç”¨

åˆ›å»º `hello.py`:

```python
import streamlit as st

# è¿™å°±æ˜¯ä¸€ä¸ªå®Œæ•´çš„ Web åº”ç”¨ï¼
st.title("æˆ‘çš„ç¬¬ä¸€ä¸ª Streamlit åº”ç”¨")
st.write("Hello World!")
```

è¿è¡Œ:
```bash
streamlit run hello.py
```

**æ€è€ƒ**: ä¸ºä»€ä¹ˆåªéœ€è¦è¿™å‡ è¡Œä»£ç å°±èƒ½åˆ›å»º Web åº”ç”¨ï¼Ÿ
- Streamlit è‡ªåŠ¨å¤„ç†äº†æœåŠ¡å™¨ã€è·¯ç”±ã€æ¸²æŸ“ç­‰å¤æ‚å·¥ä½œ
- ä»£ç ä»ä¸Šåˆ°ä¸‹æ‰§è¡Œï¼Œæ¯æ¬¡ç”¨æˆ·äº¤äº’éƒ½ä¼šé‡æ–°è¿è¡Œæ•´ä¸ªè„šæœ¬

#### åŸºæœ¬ç»„ä»¶å®è·µ

```python
import streamlit as st

# 1. æ–‡æœ¬æ˜¾ç¤º
st.title("ğŸŒ æ ‡é¢˜")
st.header("äºŒçº§æ ‡é¢˜")
st.subheader("ä¸‰çº§æ ‡é¢˜")
st.text("æ™®é€šæ–‡æœ¬")
st.markdown("**ç²—ä½“** å’Œ *æ–œä½“*")

# 2. è¾“å…¥ç»„ä»¶
name = st.text_input("ä½ çš„åå­—æ˜¯?")
age = st.slider("ä½ çš„å¹´é¾„?", 0, 100, 25)
agree = st.checkbox("æˆ‘åŒæ„")

# 3. æ˜¾ç¤ºå˜é‡
st.write(f"ä½ å¥½, {name}! ä½  {age} å²äº†ã€‚")

# 4. æŒ‰é’®
if st.button("ç‚¹å‡»æˆ‘"):
    st.success("æŒ‰é’®è¢«ç‚¹å‡»äº†!")
    st.balloons()  # å½©è›‹ï¼šæ”¾æ°”çƒåŠ¨ç”»
```

**ç»ƒä¹  1**:
åˆ›å»ºä¸€ä¸ªç®€å•çš„ BMI è®¡ç®—å™¨:
- è¾“å…¥èº«é«˜ï¼ˆå˜ç±³ï¼‰
- è¾“å…¥ä½“é‡ï¼ˆå…¬æ–¤ï¼‰
- ç‚¹å‡»æŒ‰é’®è®¡ç®— BMI
- æ˜¾ç¤ºç»“æœå’Œå¥åº·å»ºè®®

<details>
<summary>ğŸ’¡ å‚è€ƒç­”æ¡ˆ</summary>

```python
import streamlit as st

st.title("BMI è®¡ç®—å™¨")

height = st.number_input("èº«é«˜ (cm)", 100, 250, 170)
weight = st.number_input("ä½“é‡ (kg)", 30, 200, 70)

if st.button("è®¡ç®— BMI"):
    height_m = height / 100
    bmi = weight / (height_m ** 2)

    st.metric("æ‚¨çš„ BMI", f"{bmi:.2f}")

    if bmi < 18.5:
        st.info("ä½“é‡åè½»")
    elif bmi < 24:
        st.success("ä½“é‡æ­£å¸¸")
    elif bmi < 28:
        st.warning("ä½“é‡åé‡")
    else:
        st.error("è‚¥èƒ–")
```
</details>

---

### 1.2 ä¼šè¯çŠ¶æ€ (Session State)

#### ä¸ºä»€ä¹ˆéœ€è¦ Session Stateï¼Ÿ

Streamlit è„šæœ¬æ¯æ¬¡äº¤äº’éƒ½ä¼šé‡æ–°è¿è¡Œï¼Œå˜é‡ä¼šä¸¢å¤±ã€‚Session State å¯ä»¥åœ¨å¤šæ¬¡è¿è¡Œé—´ä¿æŒæ•°æ®ã€‚

#### åŸºæœ¬ç”¨æ³•

```python
import streamlit as st

# åˆå§‹åŒ– session state
if 'count' not in st.session_state:
    st.session_state.count = 0

# æ˜¾ç¤ºå½“å‰è®¡æ•°
st.write(f"è®¡æ•°: {st.session_state.count}")

# æŒ‰é’®å¢åŠ è®¡æ•°
if st.button("åŠ  1"):
    st.session_state.count += 1
    st.rerun()  # é‡æ–°è¿è¡Œè„šæœ¬ä»¥æ›´æ–°æ˜¾ç¤º
```

**å…³é”®æ¦‚å¿µ**:
- `st.session_state` æ˜¯ä¸€ä¸ªç±»ä¼¼å­—å…¸çš„å¯¹è±¡
- æ•°æ®åœ¨ç”¨æˆ·ä¼šè¯æœŸé—´æŒä¹…åŒ–
- æ¯ä¸ªç”¨æˆ·æœ‰ç‹¬ç«‹çš„ session state

#### åœ¨æ—…è¡Œä»£ç†ä¸­çš„åº”ç”¨

åœ¨ `streamlit_app.py:26-29`:

```python
# åˆå§‹åŒ– session state
if 'travel_agent' not in st.session_state:
    st.session_state.travel_agent = None  # å­˜å‚¨ AI ä»£ç†å®ä¾‹
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []    # å­˜å‚¨å¯¹è¯å†å²
```

**è®¾è®¡æ€è·¯**:
- `travel_agent`: åªåˆå§‹åŒ–ä¸€æ¬¡ï¼Œé¿å…é‡å¤åŠ è½½ï¼ˆè€—æ—¶ï¼‰
- `chat_history`: ä¿å­˜æ‰€æœ‰å¯¹è¯ï¼Œå¯ä»¥å›é¡¾å†å²è®°å½•

**ç»ƒä¹  2**:
åˆ›å»ºä¸€ä¸ªç®€å•çš„å¾…åŠäº‹é¡¹åº”ç”¨:
- æ·»åŠ æ–°ä»»åŠ¡
- æ˜¾ç¤ºæ‰€æœ‰ä»»åŠ¡
- åˆ é™¤ä»»åŠ¡
- ä½¿ç”¨ session state ä¿å­˜ä»»åŠ¡åˆ—è¡¨

<details>
<summary>ğŸ’¡ å‚è€ƒç­”æ¡ˆ</summary>

```python
import streamlit as st

st.title("ğŸ“ å¾…åŠäº‹é¡¹")

# åˆå§‹åŒ–ä»»åŠ¡åˆ—è¡¨
if 'todos' not in st.session_state:
    st.session_state.todos = []

# æ·»åŠ æ–°ä»»åŠ¡
new_todo = st.text_input("æ–°ä»»åŠ¡")
if st.button("æ·»åŠ ") and new_todo:
    st.session_state.todos.append(new_todo)
    st.rerun()

# æ˜¾ç¤ºæ‰€æœ‰ä»»åŠ¡
st.subheader("ä»»åŠ¡åˆ—è¡¨")
for i, todo in enumerate(st.session_state.todos):
    col1, col2 = st.columns([4, 1])
    with col1:
        st.write(f"{i+1}. {todo}")
    with col2:
        if st.button("åˆ é™¤", key=f"del_{i}"):
            st.session_state.todos.pop(i)
            st.rerun()
```
</details>

---

### 1.3 ç¯å¢ƒå˜é‡ä¸å®‰å…¨

#### ä¸ºä»€ä¹ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Ÿ

**é—®é¢˜**: å¦‚æœç›´æ¥åœ¨ä»£ç ä¸­å†™ API Key:
```python
api_key = "sk-proj-abc123..."  # âŒ å±é™©ï¼
```

**é£é™©**:
- æäº¤åˆ° Git åï¼Œå…¨ä¸–ç•Œéƒ½èƒ½çœ‹åˆ°
- API Key è¢«ç›—ç”¨ï¼Œäº§ç”Ÿå·¨é¢è´¹ç”¨
- å®‰å…¨æ¼æ´

#### æ­£ç¡®åšæ³•: ä½¿ç”¨ .env æ–‡ä»¶

**æ­¥éª¤ 1**: åˆ›å»º `.env` æ–‡ä»¶
```env
OPENAI_API_KEY=sk-proj-your_real_key_here
SERPER_API_KEY=your_serper_key_here
```

**æ­¥éª¤ 2**: åœ¨ä»£ç ä¸­è¯»å–
```python
from dotenv import load_dotenv
import os

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()

# è¯»å–ç¯å¢ƒå˜é‡
api_key = os.getenv("OPENAI_API_KEY")
print(f"API Key: {api_key[:10]}...")  # åªæ˜¾ç¤ºå‰ 10 ä¸ªå­—ç¬¦
```

**æ­¥éª¤ 3**: æ·»åŠ åˆ° `.gitignore`
```
.env
```

#### åœ¨æ—…è¡Œä»£ç†ä¸­çš„åº”ç”¨

åœ¨ `streamlit_app.py:113`:

```python
# ä¼˜å…ˆä» Streamlit secrets è¯»å–ï¼Œå›é€€åˆ°ç¯å¢ƒå˜é‡
openai_api_key = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")

if not openai_api_key:
    st.error("âŒ OpenAI API key not found.")
    return None
```

**è®¾è®¡æ€è·¯**:
1. **æœ¬åœ°å¼€å‘**: ä½¿ç”¨ `.env` æ–‡ä»¶
2. **äº‘ç«¯éƒ¨ç½²**: ä½¿ç”¨ Streamlit Secrets
3. **å®‰å…¨é™çº§**: å¦‚æœéƒ½æ²¡æœ‰ï¼Œæ˜¾ç¤ºå‹å¥½é”™è¯¯

**ç»ƒä¹  3**:
åˆ›å»ºä¸€ä¸ªå¤©æ°”åº”ç”¨ï¼Œå®‰å…¨åœ°ä½¿ç”¨ API Key:
1. åˆ›å»º `.env` æ–‡ä»¶å­˜å‚¨ API Key
2. è¯»å–å¹¶è°ƒç”¨å¤©æ°” API
3. å¦‚æœ Key ä¸å­˜åœ¨ï¼Œæ˜¾ç¤ºé”™è¯¯æç¤º

---

### 1.4 Python è£…é¥°å™¨ (@tool)

#### è£…é¥°å™¨æ˜¯ä»€ä¹ˆï¼Ÿ

è£…é¥°å™¨æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œå¯ä»¥ä¿®æ”¹æˆ–å¢å¼ºå¦ä¸€ä¸ªå‡½æ•°çš„è¡Œä¸ºã€‚

#### æœ€ç®€å•çš„è£…é¥°å™¨

```python
def my_decorator(func):
    def wrapper():
        print("å‡½æ•°æ‰§è¡Œå‰")
        func()
        print("å‡½æ•°æ‰§è¡Œå")
    return wrapper

@my_decorator
def say_hello():
    print("Hello!")

# è°ƒç”¨
say_hello()

# è¾“å‡º:
# å‡½æ•°æ‰§è¡Œå‰
# Hello!
# å‡½æ•°æ‰§è¡Œå
```

**ç­‰ä»·äº**:
```python
def say_hello():
    print("Hello!")

say_hello = my_decorator(say_hello)
```

#### LangChain çš„ @tool è£…é¥°å™¨

åœ¨ `streamlit_app.py:32-35`:

```python
from langchain.tools import tool

@tool
def addition(a: int, b: int) -> int:
    """Add two integers."""
    return a + b
```

**@tool è£…é¥°å™¨åšäº†ä»€ä¹ˆ**:
1. è¯»å–å‡½æ•°ç­¾åï¼ˆå‚æ•°ç±»å‹ã€è¿”å›ç±»å‹ï¼‰
2. è¯»å–æ–‡æ¡£å­—ç¬¦ä¸²ï¼ˆæè¿°åŠŸèƒ½ï¼‰
3. å°†æ™®é€š Python å‡½æ•°è½¬æ¢ä¸º LangChain Tool å¯¹è±¡
4. AI å¯ä»¥ç†è§£å¹¶è°ƒç”¨è¿™ä¸ªå·¥å…·

**å…³é”®è¦ç´ **:
- **ç±»å‹æ³¨è§£** (`a: int, b: int -> int`): å‘Šè¯‰ AI å‚æ•°ç±»å‹
- **æ–‡æ¡£å­—ç¬¦ä¸²** (`"""Add two integers."""`): å‘Šè¯‰ AI å·¥å…·ç”¨é€”
- **è¿”å›å€¼**: å·¥å…·æ‰§è¡Œçš„ç»“æœ

**ç»ƒä¹  4**:
åˆ›å»ºä»¥ä¸‹å·¥å…·ï¼Œå¹¶æµ‹è¯•:
1. `get_current_time()`: è¿”å›å½“å‰æ—¶é—´
2. `celsius_to_fahrenheit(celsius: float)`: æ¸©åº¦è½¬æ¢
3. `is_prime(n: int)`: åˆ¤æ–­æ˜¯å¦ä¸ºè´¨æ•°

<details>
<summary>ğŸ’¡ å‚è€ƒç­”æ¡ˆ</summary>

```python
from langchain.tools import tool
from datetime import datetime

@tool
def get_current_time() -> str:
    """Get the current time."""
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

@tool
def celsius_to_fahrenheit(celsius: float) -> float:
    """Convert Celsius to Fahrenheit."""
    return celsius * 9/5 + 32

@tool
def is_prime(n: int) -> bool:
    """Check if a number is prime."""
    if n < 2:
        return False
    for i in range(2, int(n**0.5) + 1):
        if n % i == 0:
            return False
    return True

# æµ‹è¯•
print(get_current_time.name)  # 'get_current_time'
print(get_current_time.description)  # 'Get the current time.'
print(get_current_time.invoke({}))  # '2025-10-17 10:30:45'
```
</details>

---

## ğŸ¤– ç¬¬äºŒé˜¶æ®µ: AI æ¡†æ¶å…¥é—¨

### 2.1 LangChain ç®€ä»‹

#### LangChain æ˜¯ä»€ä¹ˆï¼Ÿ

LangChain æ˜¯ä¸€ä¸ªæ„å»º AI åº”ç”¨çš„æ¡†æ¶ï¼Œç®€åŒ–äº†ä¸å¤§è¯­è¨€æ¨¡å‹ (LLM) äº¤äº’çš„å¤æ‚æ€§ã€‚

**ç±»æ¯”**:
- **ä¼ ç»Ÿæ–¹å¼**: ç›´æ¥è°ƒç”¨ OpenAI API = è‡ªå·±ç»„è£…ç”µè„‘
- **LangChain**: ä½¿ç”¨æ¡†æ¶ = ä¹°ç»„è£…å¥½çš„å“ç‰Œæœº

#### æ ¸å¿ƒæ¦‚å¿µ

1. **LLM (Language Model)**: è¯­è¨€æ¨¡å‹ï¼Œå¦‚ GPT-4
2. **Prompt**: æç¤ºè¯ï¼Œå‘Šè¯‰ AI è¦åšä»€ä¹ˆ
3. **Tools**: å·¥å…·ï¼ŒAI å¯ä»¥è°ƒç”¨çš„å‡½æ•°
4. **Chains**: é“¾ï¼Œå¤šä¸ªæ­¥éª¤çš„ç»„åˆ
5. **Agents**: ä»£ç†ï¼Œèƒ½è‡ªä¸»å†³ç­–çš„ AI

#### æœ€ç®€å•çš„ LangChain åº”ç”¨

```python
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
import os

# 1. åˆå§‹åŒ–æ¨¡å‹
llm = ChatOpenAI(
    model="gpt-4o",
    api_key=os.getenv("OPENAI_API_KEY")
)

# 2. å‘é€æ¶ˆæ¯
response = llm.invoke([
    HumanMessage(content="ä»€ä¹ˆæ˜¯ Python?")
])

# 3. è·å–å›å¤
print(response.content)
```

**è¾“å‡º**:
```
Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶ç®€æ´çš„è¯­æ³•å’Œå¼ºå¤§çš„åŠŸèƒ½è€Œé—»å...
```

#### æ·»åŠ ç³»ç»Ÿæç¤ºè¯

```python
from langchain_core.messages import SystemMessage, HumanMessage

messages = [
    SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªå¹½é»˜çš„ Python è€å¸ˆï¼Œç”¨æ¯”å–»æ¥è§£é‡Šæ¦‚å¿µã€‚"),
    HumanMessage(content="ä»€ä¹ˆæ˜¯å˜é‡?")
]

response = llm.invoke(messages)
print(response.content)
```

**è¾“å‡º**:
```
æƒ³è±¡å˜é‡æ˜¯ä¸€ä¸ªç›’å­ï¼Œä½ å¯ä»¥åœ¨ç›’å­é‡Œæ”¾ä¸œè¥¿ï¼ˆæ•°æ®ï¼‰ï¼Œ
è¿˜å¯ä»¥ç»™ç›’å­è´´ä¸ªæ ‡ç­¾ï¼ˆå˜é‡åï¼‰ã€‚éœ€è¦çš„æ—¶å€™ï¼Œ
çœ‹æ ‡ç­¾å°±çŸ¥é“ç›’å­é‡Œæ˜¯ä»€ä¹ˆäº†ï¼ğŸ“¦
```

**ç»ƒä¹  5**:
åˆ›å»ºä¸åŒæ€§æ ¼çš„ AI åŠ©æ‰‹:
1. ä¸¥è‚ƒçš„è€å¸ˆ
2. å¹½é»˜çš„æœ‹å‹
3. è¯—æ„çš„ä½œå®¶

é€šè¿‡ä¿®æ”¹ SystemMessage å®ç°ä¸åŒé£æ ¼ã€‚

---

### 2.2 å·¥å…· (Tools) æ·±å…¥ç†è§£

#### ä¸ºä»€ä¹ˆéœ€è¦å·¥å…·ï¼Ÿ

**é—®é¢˜**: GPT-4 çš„çŸ¥è¯†æˆªæ­¢åˆ° 2024 å¹´åˆ
- ä¸çŸ¥é“ä»Šå¤©çš„å¤©æ°”
- ä¸çŸ¥é“å®æ—¶è‚¡ç¥¨ä»·æ ¼
- ä¸èƒ½åšå¤æ‚æ•°å­¦è®¡ç®—

**è§£å†³**: ç»™ AI æä¾›å·¥å…·ï¼

#### å·¥å…·çš„å·¥ä½œåŸç†

```
ç”¨æˆ·: "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·?"
  â†“
AI æ€è€ƒ: "æˆ‘éœ€è¦æŸ¥è¯¢å¤©æ°”ï¼Œä½¿ç”¨ get_weather å·¥å…·"
  â†“
è°ƒç”¨å·¥å…·: get_weather("åŒ—äº¬")
  â†“
å·¥å…·è¿”å›: "åŒ—äº¬ï¼Œæ™´ï¼Œ25Â°Cï¼Œç©ºæ°”è´¨é‡è‰¯å¥½"
  â†“
AI æ•´åˆ: "åŒ—äº¬ä»Šå¤©å¤©æ°”æ™´æœ—ï¼Œæ¸©åº¦ 25Â°Cï¼Œç©ºæ°”è´¨é‡è‰¯å¥½ï¼Œé€‚åˆå‡ºè¡Œï¼"
  â†“
è¿”å›ç”¨æˆ·
```

#### åˆ›å»ºå¤©æ°”æŸ¥è¯¢å·¥å…·

åœ¨ `streamlit_app.py:54-66`:

```python
@tool
def get_weather(city: str) -> str:
    """Fetches the current weather of the city from OpenWeatherMap."""
    try:
        # è·å– API Key
        weather_api_key = st.secrets.get("OPENWEATHERMAP_API_KEY") or \
                         os.getenv("OPENWEATHERMAP_API_KEY")

        if weather_api_key:
            # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆAPI wrapper éœ€è¦ï¼‰
            os.environ["OPENWEATHERMAP_API_KEY"] = weather_api_key

            # åˆ›å»ºå¤©æ°” API wrapper
            weather = OpenWeatherMapAPIWrapper()

            # è°ƒç”¨ API
            return weather.run(city)
        else:
            # æ²¡æœ‰ API Key çš„å‹å¥½é”™è¯¯
            return f"Weather API key not available. Cannot get weather for {city}."

    except Exception as e:
        # æ•è·æ‰€æœ‰é”™è¯¯ï¼Œè¿”å›æœ‰ç”¨çš„ä¿¡æ¯
        return f"Weather data unavailable for {city}. Error: {str(e)}"
```

**è®¾è®¡æ€è·¯è§£æ**:

1. **æ¸…æ™°çš„æ–‡æ¡£å­—ç¬¦ä¸²**: AI é€šè¿‡è¿™ä¸ªç†è§£å·¥å…·ç”¨é€”
   ```python
   """Fetches the current weather of the city from OpenWeatherMap."""
   ```

2. **ç±»å‹æ³¨è§£**: å‘Šè¯‰ AI å‚æ•°å’Œè¿”å›å€¼ç±»å‹
   ```python
   def get_weather(city: str) -> str:
   ```

3. **çµæ´»çš„é…ç½®**: æ”¯æŒå¤šç§é…ç½®æ–¹å¼
   ```python
   # ä¼˜å…ˆçº§: Streamlit secrets > ç¯å¢ƒå˜é‡
   weather_api_key = st.secrets.get(...) or os.getenv(...)
   ```

4. **ä¼˜é›…çš„é”™è¯¯å¤„ç†**: ä¸å´©æºƒï¼Œè¿”å›æœ‰ç”¨ä¿¡æ¯
   ```python
   except Exception as e:
       return f"Error: {str(e)}"  # AI èƒ½ç†è§£çš„é”™è¯¯ä¿¡æ¯
   ```

5. **ç¯å¢ƒå˜é‡è®¾ç½®**: æŸäº›åº“éœ€è¦ä»ç¯å¢ƒå˜é‡è¯»å–
   ```python
   os.environ["OPENWEATHERMAP_API_KEY"] = weather_api_key
   ```

#### å·¥å…·çš„æœ€ä½³å®è·µ

**âœ… å¥½çš„å·¥å…·**:
```python
@tool
def calculate_mortgage(
    principal: float,
    annual_rate: float,
    years: int
) -> dict:
    """
    Calculate monthly mortgage payment.

    Args:
        principal: Loan amount in dollars
        annual_rate: Annual interest rate (e.g., 5.5 for 5.5%)
        years: Loan term in years

    Returns:
        Dictionary with monthly_payment and total_interest
    """
    monthly_rate = annual_rate / 100 / 12
    num_payments = years * 12

    monthly_payment = principal * (monthly_rate * (1 + monthly_rate)**num_payments) / \
                     ((1 + monthly_rate)**num_payments - 1)

    total_paid = monthly_payment * num_payments
    total_interest = total_paid - principal

    return {
        "monthly_payment": round(monthly_payment, 2),
        "total_interest": round(total_interest, 2),
        "total_paid": round(total_paid, 2)
    }
```

**ç‰¹ç‚¹**:
- è¯¦ç»†çš„æ–‡æ¡£è¯´æ˜å‚æ•°å’Œè¿”å›å€¼
- æ¸…æ™°çš„ç±»å‹æ³¨è§£
- è¿”å›ç»“æ„åŒ–æ•°æ®ï¼ˆå­—å…¸ï¼‰
- é”™è¯¯å¤„ç†ï¼ˆè™½ç„¶è¿™é‡Œæ²¡æ˜¾ç¤ºï¼‰

**âŒ ä¸å¥½çš„å·¥å…·**:
```python
@tool
def calc(a, b, op):  # ç±»å‹ä¸æ¸…æ™°
    """Do calculation"""  # æè¿°å¤ªæ¨¡ç³Š
    if op == "+":
        return a + b
    # æ²¡æœ‰é”™è¯¯å¤„ç†ï¼Œop æ˜¯å…¶ä»–å€¼ä¼šå´©æºƒ
```

**ç»ƒä¹  6**:
åˆ›å»ºä¸€ä¸ªè´§å¸è½¬æ¢å·¥å…·:
- è¾“å…¥: é‡‘é¢ã€æºè´§å¸ã€ç›®æ ‡è´§å¸
- ä½¿ç”¨å›ºå®šæ±‡ç‡ï¼ˆæˆ–è°ƒç”¨å®æ—¶ APIï¼‰
- è¿”å›è½¬æ¢åçš„é‡‘é¢
- åŒ…å«å®Œæ•´çš„ç±»å‹æ³¨è§£å’Œæ–‡æ¡£

<details>
<summary>ğŸ’¡ å‚è€ƒç­”æ¡ˆ</summary>

```python
@tool
def convert_currency(
    amount: float,
    from_currency: str,
    to_currency: str
) -> dict:
    """
    Convert amount from one currency to another.

    Args:
        amount: Amount to convert
        from_currency: Source currency code (e.g., 'USD', 'EUR', 'CNY')
        to_currency: Target currency code

    Returns:
        Dictionary with converted amount and exchange rate
    """
    # ç®€åŒ–ç‰ˆï¼šå›ºå®šæ±‡ç‡ï¼ˆå®é™…åº”ç”¨åº”è°ƒç”¨ APIï¼‰
    rates = {
        ('USD', 'CNY'): 7.2,
        ('CNY', 'USD'): 0.139,
        ('USD', 'EUR'): 0.92,
        ('EUR', 'USD'): 1.09,
        ('EUR', 'CNY'): 7.83,
        ('CNY', 'EUR'): 0.128,
    }

    # ç›¸åŒè´§å¸
    if from_currency == to_currency:
        return {
            "original_amount": amount,
            "converted_amount": amount,
            "exchange_rate": 1.0,
            "from": from_currency,
            "to": to_currency
        }

    # æŸ¥æ‰¾æ±‡ç‡
    rate_key = (from_currency.upper(), to_currency.upper())
    if rate_key not in rates:
        return {
            "error": f"Exchange rate from {from_currency} to {to_currency} not available"
        }

    rate = rates[rate_key]
    converted = round(amount * rate, 2)

    return {
        "original_amount": amount,
        "converted_amount": converted,
        "exchange_rate": rate,
        "from": from_currency,
        "to": to_currency
    }
```
</details>

---

### 2.3 å°†å·¥å…·ç»‘å®šåˆ° LLM

#### åŸºæœ¬æµç¨‹

åœ¨ `streamlit_app.py:172-176`:

```python
# 1. å®šä¹‰æ‰€æœ‰å·¥å…·
tools = [
    addition, multiply, division, substraction,  # æ•°å­¦å·¥å…·
    get_weather,                                 # å¤©æ°”å·¥å…·
    search_google, search_duck,                  # æœç´¢å·¥å…·
    repl_tool,                                   # Python REPL
    youtube_search                               # è§†é¢‘æœç´¢
]

# 2. å°†å·¥å…·ç»‘å®šåˆ° LLM
llm_with_tools = llm.bind_tools(tools)
```

**bind_tools åšäº†ä»€ä¹ˆ**:
1. å°†å·¥å…·åˆ—è¡¨è½¬æ¢ä¸º JSON Schema
2. å‘Šè¯‰ GPT-4 æœ‰å“ªäº›å·¥å…·å¯ç”¨
3. GPT-4 å¯ä»¥å†³å®šä½•æ—¶è°ƒç”¨å“ªä¸ªå·¥å…·

#### ç®€å•ç¤ºä¾‹

```python
from langchain_openai import ChatOpenAI
from langchain.tools import tool

@tool
def get_current_time() -> str:
    """Get the current time."""
    from datetime import datetime
    return datetime.now().strftime("%H:%M:%S")

@tool
def add_numbers(a: int, b: int) -> int:
    """Add two numbers."""
    return a + b

# ç»‘å®šå·¥å…·
llm = ChatOpenAI(model="gpt-4o", api_key=os.getenv("OPENAI_API_KEY"))
llm_with_tools = llm.bind_tools([get_current_time, add_numbers])

# è°ƒç”¨
response = llm_with_tools.invoke([
    HumanMessage(content="ç°åœ¨å‡ ç‚¹äº†?")
])

print(response)
```

**è¾“å‡º** (ç®€åŒ–):
```python
AIMessage(
    content='',
    tool_calls=[
        {
            'name': 'get_current_time',
            'args': {},
            'id': 'call_abc123'
        }
    ]
)
```

**æ³¨æ„**: AI è¿”å›çš„æ˜¯**å·¥å…·è°ƒç”¨è¯·æ±‚**ï¼Œè€Œä¸æ˜¯æœ€ç»ˆç­”æ¡ˆã€‚æˆ‘ä»¬éœ€è¦:
1. æ£€æµ‹åˆ° tool_calls
2. æ‰§è¡Œå·¥å…·
3. å°†ç»“æœè¿”å›ç»™ AI
4. AI ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆéœ€è¦ LangGraphï¼

---

## ğŸ¯ ç¬¬ä¸‰é˜¶æ®µ: æ ¸å¿ƒåŠŸèƒ½å®ç°

### 3.1 ç³»ç»Ÿæç¤ºè¯è®¾è®¡è‰ºæœ¯

ç³»ç»Ÿæç¤ºè¯æ˜¯ AI çš„"å·¥ä½œè¯´æ˜ä¹¦"ï¼Œè®¾è®¡å¾—å¥½ï¼ŒAI å°±èƒ½å‡†ç¡®å®Œæˆä»»åŠ¡ã€‚

#### åœ¨æ—…è¡Œä»£ç†ä¸­çš„ç³»ç»Ÿæç¤ºè¯

åœ¨ `streamlit_app.py:129-169`:

```python
system_prompt = SystemMessage("""
You are a professional AI Travel Agent. You MUST follow this EXACT process for every travel query:

STEP 1: ALWAYS call get_weather tool first for the destination city

STEP 2: ALWAYS call search_google or search_duck to find:
   - Hotels with specific prices per night
   - Top attractions with entry fees
   - Restaurants with price ranges
   - Transportation options with costs
   - CURRENCY CONVERSION: If user needs different currency, search for:
     "current exchange rate [from_currency] to [to_currency] today"

STEP 3: ALWAYS use arithmetic tools (addition, multiply) to calculate:
   - Hotel cost = daily_rate Ã— number_of_days
   - Total food cost = daily_food_budget Ã— number_of_days
   - Total attraction costs = sum of all entry fees
   - Currency conversion = amount Ã— exchange_rate (from search)
   - Grand total = hotel + food + attractions + transport

STEP 4: ALWAYS call youtube_search for relevant travel videos

STEP 5: Create detailed day-by-day itinerary with REAL costs from your searches

MANDATORY RULES:
- For currency conversion: SEARCH for current exchange rates, don't guess
- Use ACTUAL data from tool calls, never make up prices
- Show detailed cost breakdown with calculations
- Include weather information from the weather tool
- Provide YouTube video links from your search

FORMAT your response as:
## ğŸŒ¤ï¸ Weather Information
## ğŸ’± Currency Conversion
## ğŸ›ï¸ Attractions & Activities
## ğŸ¨ Hotels & Accommodation
## ğŸ“… Daily Itinerary
## ğŸ’° Cost Breakdown
## ğŸ¥ YouTube Resources
## ğŸ“‹ Summary
""")
```

#### ç³»ç»Ÿæç¤ºè¯è®¾è®¡åŸåˆ™

**1. æ˜ç¡®è§’è‰²å®šä½**
```python
"You are a professional AI Travel Agent."
```
- å‘Šè¯‰ AI å®ƒæ˜¯è°
- è®¾å®šä¸“ä¸šé¢†åŸŸ

**2. æ¸…æ™°çš„æ­¥éª¤æŒ‡ç¤º**
```python
"STEP 1: ALWAYS call get_weather tool first"
"STEP 2: ALWAYS call search_google..."
```
- ä½¿ç”¨ "ALWAYS"ã€"MUST" ç­‰å¼ºåˆ¶æ€§è¯æ±‡
- æŒ‰é¡ºåºåˆ—å‡ºæ­¥éª¤
- æ¯ä¸ªæ­¥éª¤éƒ½å¾ˆå…·ä½“

**3. å…·ä½“çš„è§„åˆ™**
```python
"MANDATORY RULES:
- For currency conversion: SEARCH for current exchange rates, don't guess
- Use ACTUAL data from tool calls, never make up prices"
```
- é˜²æ­¢ AI "å¹»è§‰"ï¼ˆç¼–é€ ä¿¡æ¯ï¼‰
- å¼ºè°ƒä½¿ç”¨çœŸå®æ•°æ®

**4. æ ¼å¼è¦æ±‚**
```python
"FORMAT your response as:
## ğŸŒ¤ï¸ Weather Information
## ğŸ’± Currency Conversion"
```
- ç»Ÿä¸€è¾“å‡ºæ ¼å¼
- æå‡ç”¨æˆ·ä½“éªŒ

#### æç¤ºè¯ä¼˜åŒ–æŠ€å·§

**âŒ æ¨¡ç³Šçš„æç¤ºè¯**:
```python
"å¸®ç”¨æˆ·è§„åˆ’æ—…è¡Œ"
```
**é—®é¢˜**:
- AI ä¸çŸ¥é“è¦åšä»€ä¹ˆ
- å¯èƒ½å¿˜è®°æŸ¥å¤©æ°”
- å¯èƒ½ç¼–é€ ä»·æ ¼

**âœ… æ¸…æ™°çš„æç¤ºè¯**:
```python
"You are a travel agent. Follow these steps:
1. Call get_weather for the destination
2. Search for hotel prices
3. Calculate total cost
4. Return a detailed itinerary"
```

**ç»ƒä¹  7**:
ä¸ºä»¥ä¸‹åœºæ™¯è®¾è®¡ç³»ç»Ÿæç¤ºè¯:
1. å¥èº«æ•™ç»ƒ AIï¼ˆåˆ¶å®šè®­ç»ƒè®¡åˆ’ï¼‰
2. è¥å…»å¸ˆ AIï¼ˆè®¾è®¡é¥®é£Ÿæ–¹æ¡ˆï¼‰
3. å­¦ä¹ åŠ©æ‰‹ AIï¼ˆåˆ¶å®šå­¦ä¹ è®¡åˆ’ï¼‰

è¦æ±‚:
- æ˜ç¡®è§’è‰²
- 3-5 ä¸ªæ­¥éª¤
- 2-3 æ¡è§„åˆ™
- è¾“å‡ºæ ¼å¼

---

### 3.2 ä¼šè¯å†å²ç®¡ç†

#### ä¸ºä»€ä¹ˆéœ€è¦å†å²è®°å½•ï¼Ÿ

```
ç”¨æˆ·: "æˆ‘æƒ³å»å·´é»"
AI: "å¥½çš„ï¼Œç»™ä½ è§„åˆ’å·´é»è¡Œç¨‹..."

ç”¨æˆ·: "é‚£é‡Œçš„å¤©æ°”æ€ä¹ˆæ ·?"
AI: "ä½ æƒ³å»å“ªé‡Œï¼Ÿ"  âŒ AI å¿˜è®°äº†ä¹‹å‰çš„å¯¹è¯
```

**è§£å†³**: ä¿å­˜å¯¹è¯å†å²

#### å®ç°æ–¹å¼

åœ¨ `streamlit_app.py:29`:

```python
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
```

åœ¨ `streamlit_app.py:305-308`:

```python
# ä¿å­˜åˆ°å†å²è®°å½•
st.session_state.chat_history.append({
    "query": query,
    "response": final_response
})
```

#### å®Œæ•´ç¤ºä¾‹: å¸¦å†å²çš„èŠå¤©åº”ç”¨

```python
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

# åˆå§‹åŒ–
if 'messages' not in st.session_state:
    st.session_state.messages = []

llm = ChatOpenAI(model="gpt-4o", api_key=os.getenv("OPENAI_API_KEY"))

st.title("ğŸ’¬ èŠå¤©åº”ç”¨")

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    if isinstance(msg, HumanMessage):
        st.chat_message("user").write(msg.content)
    elif isinstance(msg, AIMessage):
        st.chat_message("assistant").write(msg.content)

# ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯´ç‚¹ä»€ä¹ˆ..."):
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append(HumanMessage(content=prompt))
    st.chat_message("user").write(prompt)

    # è·å– AI å›å¤
    with st.chat_message("assistant"):
        with st.spinner("æ€è€ƒä¸­..."):
            response = llm.invoke(st.session_state.messages)
            st.write(response.content)

    # æ·»åŠ  AI æ¶ˆæ¯
    st.session_state.messages.append(AIMessage(content=response.content))
```

**å…³é”®ç‚¹**:
- ä½¿ç”¨ `LangChain` çš„æ¶ˆæ¯ç±»å‹
- å®Œæ•´çš„å¯¹è¯å†å²ä¼ é€’ç»™ LLM
- AI èƒ½ç†è§£ä¸Šä¸‹æ–‡

**ç»ƒä¹  8**:
æ‰©å±•èŠå¤©åº”ç”¨:
1. æ·»åŠ "æ¸…ç©ºå†å²"æŒ‰é’®
2. é™åˆ¶å†å²è®°å½•æœ€å¤š 10 æ¡ï¼ˆèŠ‚çœ tokenï¼‰
3. æ·»åŠ ç³»ç»Ÿæç¤ºè¯ï¼Œè®© AI æ‰®æ¼”ç‰¹å®šè§’è‰²

---

### 3.3 é”™è¯¯å¤„ç†ç­–ç•¥

#### ä¸ºä»€ä¹ˆéœ€è¦é”™è¯¯å¤„ç†ï¼Ÿ

**ç°å®æƒ…å†µ**:
- API å¯èƒ½å¤±è´¥ï¼ˆç½‘ç»œé—®é¢˜ã€é…é¢ç”¨å°½ï¼‰
- ç”¨æˆ·è¾“å…¥å¯èƒ½æ— æ•ˆ
- ç¬¬ä¸‰æ–¹æœåŠ¡å¯èƒ½å®•æœº

**ä¸å¤„ç†é”™è¯¯çš„åæœ**:
```python
weather = OpenWeatherMapAPIWrapper()
result = weather.run(city)  # å¦‚æœ API key æ— æ•ˆï¼Œç¨‹åºå´©æºƒ
```

#### é”™è¯¯å¤„ç†æ¨¡å¼

**æ¨¡å¼ 1: Try-Except-Return**

åœ¨ `streamlit_app.py:54-66`:

```python
@tool
def get_weather(city: str) -> str:
    """Fetches the current weather."""
    try:
        weather_api_key = st.secrets.get("OPENWEATHERMAP_API_KEY") or \
                         os.getenv("OPENWEATHERMAP_API_KEY")

        if weather_api_key:
            os.environ["OPENWEATHERMAP_API_KEY"] = weather_api_key
            weather = OpenWeatherMapAPIWrapper()
            return weather.run(city)
        else:
            # å‹å¥½é”™è¯¯: API key ç¼ºå¤±
            return f"Weather API key not available. Cannot get weather for {city}."

    except Exception as e:
        # å‹å¥½é”™è¯¯: å…¶ä»–ä»»ä½•é—®é¢˜
        return f"Weather data unavailable for {city}. Error: {str(e)}"
```

**è®¾è®¡æ€è·¯**:
1. **ä¸æŠ›å‡ºå¼‚å¸¸**: è¿”å›é”™è¯¯ä¿¡æ¯å­—ç¬¦ä¸²
2. **AI å‹å¥½**: AI èƒ½ç†è§£é”™è¯¯ï¼Œç»§ç»­å·¥ä½œ
3. **å¤šå±‚æ£€æŸ¥**: å…ˆæ£€æŸ¥ API keyï¼Œå†å°è¯•è°ƒç”¨

**æ¨¡å¼ 2: Try-Except with Fallback**

åœ¨ `streamlit_app.py:68-81`:

```python
@tool
def search_google(query: str) -> str:
    """Fetches details from Google Serper API."""
    try:
        serper_api_key = st.secrets.get("SERPER_API_KEY") or os.getenv("SERPER_API_KEY")
        if serper_api_key:
            os.environ["SERPER_API_KEY"] = serper_api_key
            search_serper = GoogleSerperAPIWrapper()
            return search_serper.run(query)
        else:
            # å›é€€åˆ° DuckDuckGo
            return search_duck(query)
    except Exception as e:
        return f"Google search unavailable, trying alternative search. Error: {str(e)}"
```

**è®¾è®¡æ€è·¯**:
- **ä¼˜é›…é™çº§**: ä¸»è¦æœåŠ¡å¤±è´¥æ—¶ï¼Œä½¿ç”¨å¤‡ç”¨æœåŠ¡
- **ç”¨æˆ·æ— æ„ŸçŸ¥**: è‡ªåŠ¨åˆ‡æ¢ï¼Œä¸éœ€è¦ç”¨æˆ·å¹²é¢„

**æ¨¡å¼ 3: User-Facing Error Handling**

åœ¨ `streamlit_app.py:278-280`:

```python
if not openai_key:
    st.error("âŒ OpenAI API key is required. Please add it to Streamlit secrets.")
    return  # åœæ­¢æ‰§è¡Œ
```

**è®¾è®¡æ€è·¯**:
- **é˜»æ–­æ€§é”™è¯¯**: æ²¡æœ‰ API key å°±æ— æ³•ç»§ç»­
- **æ˜ç¡®æŒ‡å¼•**: å‘Šè¯‰ç”¨æˆ·å¦‚ä½•è§£å†³

#### é”™è¯¯å¤„ç†æœ€ä½³å®è·µ

```python
@tool
def robust_api_call(param: str) -> dict:
    """A robust API call with proper error handling."""

    # 1. å‚æ•°éªŒè¯
    if not param or len(param) < 2:
        return {
            "error": "Invalid parameter: must be at least 2 characters",
            "status": "validation_error"
        }

    # 2. API Key æ£€æŸ¥
    api_key = os.getenv("API_KEY")
    if not api_key:
        return {
            "error": "API key not configured",
            "status": "configuration_error",
            "hint": "Please add API_KEY to your environment variables"
        }

    # 3. API è°ƒç”¨
    try:
        response = call_external_api(param, api_key)
        return {
            "data": response,
            "status": "success"
        }

    except ConnectionError as e:
        # ç½‘ç»œé—®é¢˜
        return {
            "error": f"Network error: {str(e)}",
            "status": "network_error",
            "retry": True
        }

    except ValueError as e:
        # API è¿”å›æ— æ•ˆæ•°æ®
        return {
            "error": f"Invalid response from API: {str(e)}",
            "status": "api_error"
        }

    except Exception as e:
        # å…¶ä»–æœªçŸ¥é”™è¯¯
        return {
            "error": f"Unexpected error: {str(e)}",
            "status": "unknown_error"
        }
```

**ç»ƒä¹  9**:
ä¸ºä¸€ä¸ªæ–‡ä»¶è¯»å–å·¥å…·æ·»åŠ å®Œæ•´çš„é”™è¯¯å¤„ç†:
- æ–‡ä»¶ä¸å­˜åœ¨
- æ–‡ä»¶æƒé™ä¸è¶³
- æ–‡ä»¶å†…å®¹æ ¼å¼é”™è¯¯
- æ–‡ä»¶è¿‡å¤§ï¼ˆ>10MBï¼‰

---

## ğŸŒŠ ç¬¬å››é˜¶æ®µ: LangGraph çŠ¶æ€å›¾

### 4.1 ä¸ºä»€ä¹ˆéœ€è¦ LangGraphï¼Ÿ

#### é—®é¢˜: ç®€å•çš„å·¥å…·è°ƒç”¨ä¸å¤Ÿç”¨

```python
# ç®€å•æ–¹å¼
response = llm_with_tools.invoke([HumanMessage("æŸ¥åŒ—äº¬å¤©æ°”")])

# é—®é¢˜:
# 1. AI å¯èƒ½éœ€è¦è°ƒç”¨å¤šä¸ªå·¥å…·
# 2. ä¸€ä¸ªå·¥å…·çš„ç»“æœå¯èƒ½ç”¨äºå¦ä¸€ä¸ªå·¥å…·
# 3. éœ€è¦æ¥å›å¤šæ¬¡å¯¹è¯
```

**ç¤ºä¾‹æµç¨‹**:
```
ç”¨æˆ·: "æˆ‘æƒ³å»åŒ—äº¬æ—…è¡Œ 3 å¤©ï¼Œé¢„ç®— 3000 å…ƒ"
  â†“
AI: è°ƒç”¨ get_weather("åŒ—äº¬")
  â†“
å·¥å…·è¿”å›: "åŒ—äº¬ï¼Œæ™´ï¼Œ25Â°C"
  â†“
AI: è°ƒç”¨ search_google("åŒ—äº¬é…’åº—ä»·æ ¼")
  â†“
å·¥å…·è¿”å›: "ç»æµå‹é…’åº— 300 å…ƒ/æ™š"
  â†“
AI: è°ƒç”¨ multiply(300, 3)  # è®¡ç®—é…’åº—æ€»ä»·
  â†“
å·¥å…·è¿”å›: 900
  â†“
AI: è°ƒç”¨ substraction(3000, 900)  # å‰©ä½™é¢„ç®—
  â†“
å·¥å…·è¿”å›: 2100
  â†“
AI: ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
```

**éœ€è¦ä¸€ä¸ªæ¡†æ¶æ¥ç®¡ç†è¿™ä¸ªå¤æ‚æµç¨‹** â†’ LangGraph

#### LangGraph æ˜¯ä»€ä¹ˆï¼Ÿ

LangGraph æ˜¯ä¸€ä¸ªçŠ¶æ€å›¾æ¡†æ¶ï¼Œç”¨äºæ„å»ºå¤æ‚çš„ AI å·¥ä½œæµã€‚

**æ ¸å¿ƒæ¦‚å¿µ**:
- **èŠ‚ç‚¹ (Node)**: æ‰§è¡Œç‰¹å®šä»»åŠ¡çš„å‡½æ•°
- **è¾¹ (Edge)**: èŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥
- **çŠ¶æ€ (State)**: åœ¨èŠ‚ç‚¹é—´ä¼ é€’çš„æ•°æ®
- **æ¡ä»¶è¾¹ (Conditional Edge)**: æ ¹æ®æ¡ä»¶å†³å®šä¸‹ä¸€æ­¥

### 4.2 æ„å»ºç®€å•çš„çŠ¶æ€å›¾

#### æœ€ç®€å•çš„ä¾‹å­

```python
from langgraph.graph import StateGraph, MessagesState, START, END
from langchain_core.messages import HumanMessage, SystemMessage

# å®šä¹‰èŠ‚ç‚¹å‡½æ•°
def my_node(state: MessagesState):
    """ä¸€ä¸ªç®€å•çš„èŠ‚ç‚¹ï¼Œæ·»åŠ ä¸€æ¡æ¶ˆæ¯"""
    messages = state["messages"]
    # æ·»åŠ æ–°æ¶ˆæ¯
    response = HumanMessage(content="Hello from node!")
    return {"messages": messages + [response]}

# æ„å»ºå›¾
builder = StateGraph(MessagesState)

# æ·»åŠ èŠ‚ç‚¹
builder.add_node("my_node", my_node)

# æ·»åŠ è¾¹
builder.add_edge(START, "my_node")  # å¼€å§‹ -> my_node
builder.add_edge("my_node", END)     # my_node -> ç»“æŸ

# ç¼–è¯‘
graph = builder.compile()

# ä½¿ç”¨
result = graph.invoke({
    "messages": [HumanMessage(content="Hi")]
})

print(result["messages"])
# [HumanMessage("Hi"), HumanMessage("Hello from node!")]
```

**æµç¨‹å›¾**:
```
START â†’ my_node â†’ END
```

### 4.3 æ—…è¡Œä»£ç†çš„çŠ¶æ€å›¾

åœ¨ `streamlit_app.py:185-194`:

```python
# 1. å®šä¹‰èŠ‚ç‚¹å‡½æ•°
def function_1(state: MessagesState):
    user_question = state["messages"]
    input_question = [system_prompt] + user_question
    response = llm_with_tools.invoke(input_question)
    return {"messages": [response]}

# 2. æ„å»ºçŠ¶æ€å›¾
builder = StateGraph(MessagesState)

# 3. æ·»åŠ èŠ‚ç‚¹
builder.add_node("llm_decision_step", function_1)      # LLM å†³ç­–èŠ‚ç‚¹
builder.add_node("tools", ToolNode(tools))              # å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹

# 4. æ·»åŠ è¾¹
builder.add_edge(START, "llm_decision_step")            # å¼€å§‹ â†’ LLM

# 5. æ¡ä»¶è¾¹: æ ¹æ® LLM è¾“å‡ºå†³å®šä¸‹ä¸€æ­¥
builder.add_conditional_edges(
    "llm_decision_step",
    tools_condition  # å¦‚æœéœ€è¦è°ƒç”¨å·¥å…· â†’ tools èŠ‚ç‚¹ï¼Œå¦åˆ™ â†’ END
)

builder.add_edge("tools", "llm_decision_step")          # å·¥å…· â†’ LLM (å¾ªç¯)

# 6. ç¼–è¯‘
react_graph = builder.compile()
```

**æµç¨‹å›¾**:
```
START
  â†“
llm_decision_step â†â”€â”€â”
  â†“ (æ¡ä»¶åˆ¤æ–­)        â”‚
  â”œâ”€â†’ éœ€è¦å·¥å…·? â†’ tools â”€â”˜
  â””â”€â†’ ä¸éœ€è¦? â†’ END
```

#### è¯¦ç»†è§£æ

**1. MessagesState**
```python
class MessagesState:
    messages: list[BaseMessage]  # å­˜å‚¨æ‰€æœ‰æ¶ˆæ¯
```

**2. function_1 (LLM å†³ç­–èŠ‚ç‚¹)**
```python
def function_1(state: MessagesState):
    # è·å–å½“å‰æ¶ˆæ¯
    user_question = state["messages"]

    # æ·»åŠ ç³»ç»Ÿæç¤ºè¯
    input_question = [system_prompt] + user_question

    # è°ƒç”¨ LLM (å¸¦å·¥å…·)
    response = llm_with_tools.invoke(input_question)

    # è¿”å›æ–°æ¶ˆæ¯
    return {"messages": [response]}
```

**3. ToolNode (å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹)**
```python
ToolNode(tools)  # è‡ªåŠ¨å¤„ç†å·¥å…·è°ƒç”¨
```

**åŠŸèƒ½**:
- æ£€æŸ¥ LLM å“åº”ä¸­çš„ `tool_calls`
- æ‰§è¡Œå¯¹åº”çš„å·¥å…·
- å°†ç»“æœåŒ…è£…æˆ `ToolMessage`

**4. tools_condition (æ¡ä»¶å‡½æ•°)**
```python
def tools_condition(state):
    """æ£€æŸ¥æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨"""
    last_message = state["messages"][-1]

    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        return "tools"  # å»å·¥å…·èŠ‚ç‚¹
    else:
        return END  # ç»“æŸ
```

### 4.4 æ‰§è¡Œæµç¨‹ç¤ºä¾‹

ç”¨æˆ·æŸ¥è¯¢: "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·?"

```
ã€ç¬¬ 1 è½®ã€‘
START â†’ llm_decision_step
  LLM è¾“å‡º: AIMessage(tool_calls=[{name: 'get_weather', args: {'city': 'åŒ—äº¬'}}])

æ¡ä»¶åˆ¤æ–­: æœ‰ tool_calls â†’ å‰å¾€ tools èŠ‚ç‚¹

ã€ç¬¬ 2 è½®ã€‘
tools èŠ‚ç‚¹
  æ‰§è¡Œ: get_weather("åŒ—äº¬")
  è¿”å›: ToolMessage(content="åŒ—äº¬ï¼Œæ™´ï¼Œ25Â°C")

è‡ªåŠ¨è¿”å›: llm_decision_step

ã€ç¬¬ 3 è½®ã€‘
llm_decision_step
  è¾“å…¥: [
    HumanMessage("åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·?"),
    AIMessage(tool_calls=[...]),
    ToolMessage("åŒ—äº¬ï¼Œæ™´ï¼Œ25Â°C")
  ]

  LLM è¾“å‡º: AIMessage(content="åŒ—äº¬ä»Šå¤©å¤©æ°”æ™´æœ—ï¼Œæ¸©åº¦ 25Â°C")

æ¡ä»¶åˆ¤æ–­: æ—  tool_calls â†’ END

è¿”å›ç»™ç”¨æˆ·: "åŒ—äº¬ä»Šå¤©å¤©æ°”æ™´æœ—ï¼Œæ¸©åº¦ 25Â°C"
```

**å…³é”®ç‚¹**:
- **è‡ªåŠ¨å¾ªç¯**: å·¥å…·èŠ‚ç‚¹è‡ªåŠ¨è¿”å› LLM èŠ‚ç‚¹
- **çŠ¶æ€ç´¯ç§¯**: æ¯è½®çš„æ¶ˆæ¯éƒ½æ·»åŠ åˆ°çŠ¶æ€ä¸­
- **AI å†³ç­–**: LLM å†³å®šä½•æ—¶åœæ­¢è°ƒç”¨å·¥å…·

### 4.5 å®æˆ˜: æ·»åŠ æ–°èŠ‚ç‚¹

å‡è®¾æˆ‘ä»¬æƒ³æ·»åŠ ä¸€ä¸ª"æ•°æ®éªŒè¯"èŠ‚ç‚¹ï¼Œåœ¨æœ€ç»ˆè¾“å‡ºå‰æ£€æŸ¥æ•°æ®ã€‚

```python
# 1. å®šä¹‰éªŒè¯èŠ‚ç‚¹
def validation_node(state: MessagesState):
    """éªŒè¯ AI è¾“å‡ºæ˜¯å¦åŒ…å«å¿…è¦ä¿¡æ¯"""
    last_message = state["messages"][-1]
    content = last_message.content

    # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®ä¿¡æ¯
    required_keywords = ["å¤©æ°”", "æ¸©åº¦"]
    if all(keyword in content for keyword in required_keywords):
        # éªŒè¯é€šè¿‡
        return {"messages": [HumanMessage(content="âœ… éªŒè¯é€šè¿‡")]}
    else:
        # éªŒè¯å¤±è´¥ï¼Œè¦æ±‚ AI é‡æ–°ç”Ÿæˆ
        return {"messages": [HumanMessage(content="è¯·æä¾›æ›´è¯¦ç»†çš„å¤©æ°”ä¿¡æ¯")]}

# 2. ä¿®æ”¹å›¾æ„å»º
builder = StateGraph(MessagesState)
builder.add_node("llm_decision_step", function_1)
builder.add_node("tools", ToolNode(tools))
builder.add_node("validation", validation_node)  # æ–°èŠ‚ç‚¹

builder.add_edge(START, "llm_decision_step")
builder.add_conditional_edges("llm_decision_step", tools_condition)
builder.add_edge("tools", "llm_decision_step")

# åœ¨ç»“æŸå‰æ·»åŠ éªŒè¯
builder.add_edge("llm_decision_step", "validation")
builder.add_edge("validation", END)

react_graph = builder.compile()
```

**ç»ƒä¹  10**:
è®¾è®¡ä¸€ä¸ªæ–°çš„çŠ¶æ€å›¾ï¼ŒåŒ…å«:
1. LLM èŠ‚ç‚¹
2. æœç´¢èŠ‚ç‚¹
3. æ€»ç»“èŠ‚ç‚¹
4. ç¿»è¯‘èŠ‚ç‚¹ï¼ˆå¦‚æœéœ€è¦ï¼‰

æµç¨‹:
- ç”¨æˆ·é—®é¢˜ â†’ LLM å†³ç­–
- LLM è°ƒç”¨æœç´¢
- æœç´¢ç»“æœ â†’ æ€»ç»“èŠ‚ç‚¹
- å¦‚æœç”¨æˆ·è¦æ±‚å…¶ä»–è¯­è¨€ â†’ ç¿»è¯‘èŠ‚ç‚¹
- è¿”å›æœ€ç»ˆç»“æœ

---

## ğŸš€ ç¬¬äº”é˜¶æ®µ: å®æˆ˜ç»ƒä¹ 

### 5.1 ç»ƒä¹  1: æ·»åŠ æ–°åŠŸèƒ½ - èˆªç­æœç´¢

**ä»»åŠ¡**: æ·»åŠ ä¸€ä¸ªèˆªç­ä»·æ ¼æŸ¥è¯¢å·¥å…·

**æ­¥éª¤**:

#### 1. åˆ›å»ºå·¥å…·
```python
@tool
def search_flight(
    origin: str,
    destination: str,
    date: str
) -> dict:
    """
    Search for flight prices.

    Args:
        origin: Origin city (e.g., "åŒ—äº¬")
        destination: Destination city (e.g., "ä¸Šæµ·")
        date: Travel date in YYYY-MM-DD format

    Returns:
        Dictionary with flight options and prices
    """
    # æ¨¡æ‹Ÿæ•°æ®ï¼ˆå®é™…åº”è°ƒç”¨èˆªç­ APIï¼‰
    import random

    base_price = random.randint(500, 2000)

    return {
        "origin": origin,
        "destination": destination,
        "date": date,
        "flights": [
            {
                "airline": "ä¸œæ–¹èˆªç©º",
                "departure": "08:00",
                "arrival": "10:30",
                "price": base_price
            },
            {
                "airline": "å—æ–¹èˆªç©º",
                "departure": "14:00",
                "arrival": "16:30",
                "price": base_price + 200
            },
            {
                "airline": "ä¸­å›½å›½èˆª",
                "departure": "18:00",
                "arrival": "20:30",
                "price": base_price - 100
            }
        ]
    }
```

#### 2. æ³¨å†Œå·¥å…·
```python
tools = [
    # ... ç°æœ‰å·¥å…·
    search_flight  # æ–°å·¥å…·
]
```

#### 3. æ›´æ–°ç³»ç»Ÿæç¤ºè¯
```python
system_prompt = SystemMessage("""
...
STEP 2.5: If user mentions air travel, call search_flight tool

ADDITIONAL SECTION in output:
## âœˆï¸ Flight Options
...
""")
```

#### 4. æµ‹è¯•
```
ç”¨æˆ·: "æˆ‘æƒ³ä»åŒ—äº¬é£ä¸Šæµ·ï¼Œ2025-11-01 å‡ºå‘"
é¢„æœŸè¾“å‡º: èˆªç­é€‰é¡¹å’Œä»·æ ¼
```

---

### 5.2 ç»ƒä¹  2: æ€§èƒ½ä¼˜åŒ–

**ä»»åŠ¡**: å‡å°‘ API è°ƒç”¨æ¬¡æ•°å’Œæˆæœ¬

#### ä¼˜åŒ– 1: ç¼“å­˜æœç´¢ç»“æœ

```python
import streamlit as st
from functools import lru_cache

# æ–¹æ³• 1: Streamlit ç¼“å­˜
@st.cache_data(ttl=3600)  # ç¼“å­˜ 1 å°æ—¶
def cached_search(query: str) -> str:
    """ç¼“å­˜çš„æœç´¢å‡½æ•°"""
    search = DuckDuckGoSearchRun()
    return search.invoke(query)

# æ–¹æ³• 2: Python LRU ç¼“å­˜
@lru_cache(maxsize=100)
def cached_weather(city: str) -> str:
    """ç¼“å­˜çš„å¤©æ°”æŸ¥è¯¢"""
    weather = OpenWeatherMapAPIWrapper()
    return weather.run(city)

# åœ¨å·¥å…·ä¸­ä½¿ç”¨
@tool
def get_weather(city: str) -> str:
    """Get weather with caching."""
    return cached_weather(city)
```

#### ä¼˜åŒ– 2: å‡å°‘ Token ä½¿ç”¨

```python
# åŸæ¥: 2000 tokens
llm = ChatOpenAI(
    model="gpt-4o",
    max_tokens=2000  # æ¯æ¬¡æœ€å¤šç”Ÿæˆ 2000 tokens
)

# ä¼˜åŒ–: 1000 tokens
llm = ChatOpenAI(
    model="gpt-4o",
    max_tokens=1000  # å‡å°‘ 50%
)

# è¿›ä¸€æ­¥ä¼˜åŒ–: ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹
llm = ChatOpenAI(
    model="gpt-3.5-turbo",  # æˆæœ¬é™ä½ 90%
    max_tokens=1000
)
```

#### ä¼˜åŒ– 3: é™åˆ¶å†å²è®°å½•é•¿åº¦

```python
# åªä¿ç•™æœ€è¿‘ 5 è½®å¯¹è¯
if len(st.session_state.messages) > 10:  # 5 è½® Ã— 2 æ¡æ¶ˆæ¯
    # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ + æœ€è¿‘ 10 æ¡
    st.session_state.messages = (
        [st.session_state.messages[0]] +  # ç³»ç»Ÿæ¶ˆæ¯
        st.session_state.messages[-10:]    # æœ€è¿‘ 10 æ¡
    )
```

---

### 5.3 ç»ƒä¹  3: æ·»åŠ ç”¨æˆ·è®¤è¯

**ä»»åŠ¡**: æ·»åŠ ç®€å•çš„ç”¨æˆ·è®¤è¯

```python
import streamlit as st

def check_password():
    """è¿”å› `True` å¦‚æœç”¨æˆ·è¾“å…¥äº†æ­£ç¡®çš„å¯†ç ."""

    def password_entered():
        """æ£€æŸ¥å¯†ç æ˜¯å¦æ­£ç¡®."""
        if st.session_state["password"] == "your_secret_password":
            st.session_state["password_correct"] = True
            del st.session_state["password"]  # åˆ é™¤å¯†ç 
        else:
            st.session_state["password_correct"] = False

    # é¦–æ¬¡è®¿é—®æˆ–å¯†ç é”™è¯¯
    if "password_correct" not in st.session_state:
        st.text_input(
            "å¯†ç ",
            type="password",
            on_change=password_entered,
            key="password",
        )
        return False

    # å¯†ç é”™è¯¯
    elif not st.session_state["password_correct"]:
        st.text_input(
            "å¯†ç ",
            type="password",
            on_change=password_entered,
            key="password",
        )
        st.error("ğŸ˜• å¯†ç é”™è¯¯")
        return False

    # å¯†ç æ­£ç¡®
    else:
        return True

# åœ¨ main å‡½æ•°å¼€å¤´ä½¿ç”¨
def main():
    if not check_password():
        st.stop()  # åœæ­¢æ‰§è¡Œ

    # ä¸»åº”ç”¨é€»è¾‘
    st.title("ğŸŒ AI Travel Agent")
    # ...
```

---

## ğŸ“Š å­¦ä¹ æˆæœæ£€éªŒ

### çŸ¥è¯†ç‚¹æ¸…å•

å®Œæˆæ‰€æœ‰ç»ƒä¹ åï¼Œæ‚¨åº”è¯¥èƒ½å¤Ÿ:

**åŸºç¡€ (ç¬¬ä¸€é˜¶æ®µ)**
- [ ] åˆ›å»º Streamlit åº”ç”¨
- [ ] ä½¿ç”¨ session_state ç®¡ç†çŠ¶æ€
- [ ] å®‰å…¨åœ°ä½¿ç”¨ç¯å¢ƒå˜é‡
- [ ] ç†è§£ Python è£…é¥°å™¨

**AI æ¡†æ¶ (ç¬¬äºŒé˜¶æ®µ)**
- [ ] è°ƒç”¨ OpenAI API
- [ ] ä½¿ç”¨ LangChain åˆ›å»ºå¯¹è¯
- [ ] åˆ›å»ºè‡ªå®šä¹‰å·¥å…·
- [ ] å°†å·¥å…·ç»‘å®šåˆ° LLM

**æ ¸å¿ƒåŠŸèƒ½ (ç¬¬ä¸‰é˜¶æ®µ)**
- [ ] è®¾è®¡æœ‰æ•ˆçš„ç³»ç»Ÿæç¤ºè¯
- [ ] ç®¡ç†å¯¹è¯å†å²
- [ ] å®ç°é”™è¯¯å¤„ç†
- [ ] ä¼˜åŒ–ç”¨æˆ·ä½“éªŒ

**é«˜çº§ç‰¹æ€§ (ç¬¬å››é˜¶æ®µ)**
- [ ] æ„å»º LangGraph çŠ¶æ€å›¾
- [ ] ç†è§£èŠ‚ç‚¹å’Œè¾¹çš„æ¦‚å¿µ
- [ ] å®ç°æ¡ä»¶é€»è¾‘
- [ ] è°ƒè¯•å¤æ‚å·¥ä½œæµ

**å®æˆ˜èƒ½åŠ› (ç¬¬äº”é˜¶æ®µ)**
- [ ] æ·»åŠ æ–°åŠŸèƒ½
- [ ] ä¼˜åŒ–æ€§èƒ½å’Œæˆæœ¬
- [ ] éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
- [ ] ç»´æŠ¤å’Œç›‘æ§åº”ç”¨

---

## ğŸ¯ ä¸‹ä¸€æ­¥å­¦ä¹ å»ºè®®

### 1. æ·±å…¥ LangChain
- [LangChain å®˜æ–¹æ–‡æ¡£](https://python.langchain.com)
- å­¦ä¹  Chain å’Œ LCEL
- äº†è§£ Memory å’Œ Retrieval

### 2. æŒæ¡ LangGraph
- [LangGraph æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)
- æ„å»ºå¤šä»£ç†ç³»ç»Ÿ
- å®ç°äººæœºåä½œ

### 3. æå‡ Prompt Engineering
- [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)
- Few-shot learning
- Chain-of-thought prompting

### 4. å­¦ä¹ å‘é‡æ•°æ®åº“
- Pinecone / Weaviate
- å®ç° RAG (Retrieval Augmented Generation)
- æ„å»ºçŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ

### 5. é¡¹ç›®å®æˆ˜
å»ºè®®é¡¹ç›®:
1. **å®¢æœæœºå™¨äºº**: å¤šè½®å¯¹è¯ + çŸ¥è¯†åº“
2. **ä»£ç åŠ©æ‰‹**: ç†è§£éœ€æ±‚ + ç”Ÿæˆä»£ç  + è°ƒè¯•
3. **æ•°æ®åˆ†æåŠ©æ‰‹**: è¯»å–æ•°æ® + åˆ†æ + å¯è§†åŒ–

---

## ğŸ’¡ å­¦ä¹ æŠ€å·§

### 1. åŠ¨æ‰‹å®è·µ
- æ¯ä¸ªä»£ç ç¤ºä¾‹éƒ½è¦è‡ªå·±æ•²ä¸€é
- ä¿®æ”¹å‚æ•°ï¼Œè§‚å¯Ÿç»“æœå˜åŒ–
- å°è¯•ç ´åä»£ç ï¼Œç†è§£é”™è¯¯

### 2. é˜…è¯»æºç 
```python
# å¥½å¥‡ ToolNode å¦‚ä½•å·¥ä½œï¼Ÿ
from langgraph.prebuilt import ToolNode
import inspect

print(inspect.getsource(ToolNode))
```

### 3. ä½¿ç”¨è°ƒè¯•å·¥å…·
```python
# åœ¨å…³é”®ä½ç½®æ·»åŠ æ‰“å°
def function_1(state: MessagesState):
    print(f"ğŸ“¥ æ”¶åˆ°æ¶ˆæ¯: {state['messages']}")

    response = llm_with_tools.invoke(...)

    print(f"ğŸ“¤ AI å“åº”: {response}")
    print(f"ğŸ”§ å·¥å…·è°ƒç”¨: {getattr(response, 'tool_calls', None)}")

    return {"messages": [response]}
```

### 4. å»ºç«‹çŸ¥è¯†ä½“ç³»
- åˆ›å»ºæ€ç»´å¯¼å›¾
- å†™å­¦ä¹ ç¬”è®°
- æ•™åˆ«äººï¼ˆæœ€å¥½çš„å­¦ä¹ æ–¹æ³•ï¼‰

### 5. åŠ å…¥ç¤¾åŒº
- [LangChain Discord](https://discord.gg/langchain)
- [Streamlit Forum](https://discuss.streamlit.io/)
- GitHub Discussions

---

## ğŸ“ ç»“è¯­

æ­å–œæ‚¨å®Œæˆäº†å­¦ä¹ æŒ‡å—ï¼ç°åœ¨æ‚¨å·²ç»å…·å¤‡äº†:

âœ… æ„å»º AI åº”ç”¨çš„åŸºç¡€çŸ¥è¯†
âœ… ä½¿ç”¨ LangChain å’Œ LangGraph çš„èƒ½åŠ›
âœ… è®¾è®¡å¤æ‚å·¥ä½œæµçš„æ€ç»´
âœ… è§£å†³å®é™…é—®é¢˜çš„ç»éªŒ

**è®°ä½**:
- å­¦ä¹ æ˜¯ä¸€ä¸ªæ¸è¿›çš„è¿‡ç¨‹ï¼Œä¸è¦ç€æ€¥
- é‡åˆ°é—®é¢˜å¾ˆæ­£å¸¸ï¼ŒæŸ¥æ–‡æ¡£ã€é—®ç¤¾åŒº
- æœ€å¥½çš„å­¦ä¹ æ–¹å¼æ˜¯æ„å»ºè‡ªå·±çš„é¡¹ç›®

**ç°åœ¨ï¼Œå¼€å§‹æ„å»ºæ‚¨è‡ªå·±çš„ AI åº”ç”¨å§ï¼** ğŸš€

---

**æœ€åæ›´æ–°**: 2025-10-17
**ä½œè€…**: AI Travel Agent Team
**ç‰ˆæœ¬**: 1.0.0
